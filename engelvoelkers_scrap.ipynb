{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ab23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import warnings\n",
    "from itertools import chain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2527fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para convertir los textos en numero\n",
    "def text_to_num(text, dec_sep=None, mil_sep=\".\"):\n",
    "\n",
    "    if (type(text)==int) or (type(text)==float):\n",
    "        return text\n",
    "    if (type(text)==bool):\n",
    "        return int(text)\n",
    "    \n",
    "    # Primero quitaré los separadores de millares\n",
    "    # Es posible que por equivocación se use el mismo dec_sep que mil_sep, por ello se cambiará mil_sep\n",
    "    if dec_sep == mil_sep:\n",
    "        change_sep = {\".\":\",\", \",\":\".\"}\n",
    "        mil_sep = change_sep[dec_sep]\n",
    "        warnings.warn(f\"Using same decimal separator as mil separator, mil_sep will be {change_sep[dec_sep]}\")\n",
    "\n",
    "    text = text.replace(mil_sep, \"\")\n",
    "\n",
    "\n",
    "    if not dec_sep:\n",
    "        numeros = re.findall(r'\\d+', text)\n",
    "        numero = int(\"\".join(numeros))\n",
    "\n",
    "    else: \n",
    "        if not dec_sep:\n",
    "            raise ValueError(\"Error: Introduce un separador decimal para la variable [dec_sep]\")\n",
    "        else:\n",
    "            match = re.search(fr'\\d+{re.escape(dec_sep)}\\d+', text)\n",
    "            if match:\n",
    "                num_str = match.group(0)\n",
    "                if dec_sep == \",\":\n",
    "                    num_str = num_str.replace(\",\", \".\")\n",
    "                numero = float(num_str)\n",
    "\n",
    "    \n",
    "    return numero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ff3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------\n",
    "# Funcion para leer cada pagina de cada casa\n",
    "def read_link(link, location):\n",
    "    url = link\n",
    "     # Obtener el HTML de la página\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "    v_independ = {\n",
    "            \"link\": link,\n",
    "            \"title\": None,\n",
    "            \"coment\": None,\n",
    "            \"price\": 0,\n",
    "            \"location\": location,\n",
    "            \"num_photos\": 0,\n",
    "            \"property_type\": None,\n",
    "            \"condition\": None,\n",
    "            \"num_rooms\": 0,\n",
    "            \"num_bedrooms\":0,\n",
    "            \"num_baths\":0,\n",
    "            \"floor_number\": 0,\n",
    "            \"garage\": False,\n",
    "            \"total_surf\":0,\n",
    "            \"living_surf\":0,\n",
    "            \"usable_area\":0,\n",
    "            \"floor_type\": None,\n",
    "            \"construc_year\":1900,\n",
    "            \"energy_cert_avail\": False,\n",
    "            \"heating\": None,\n",
    "            \"others\": None\n",
    "        }\n",
    "\n",
    "    # num_photos\n",
    "    button = soup.find('button', {'aria-label': 'Galería'})\n",
    "    if button:\n",
    "        num_photos = button.find('span').text.strip()\n",
    "        num_photos = int(num_photos.split(\"/\")[-1])\n",
    "        v_independ[\"num_photos\"] = num_photos\n",
    "\n",
    "    # title\n",
    "    titulo = soup.find('h1', {'data-test-id': 'expose-headline'})\n",
    "    if titulo:\n",
    "        titulo = titulo.text.strip()\n",
    "        v_independ[\"title\"] = titulo\n",
    "\n",
    "    # price\n",
    "    precio = soup.find('span', {'data-test-id': 'expose-price-value'})\n",
    "    if precio:\n",
    "        precio = precio.text.strip()\n",
    "        precio = text_to_num(precio)\n",
    "        v_independ[\"price\"] = precio\n",
    "\n",
    "\n",
    "    diccionario = {\n",
    "            \"property_type\": [\"propiedad\"],\n",
    "            \"condition\": [\"Condic\"],\n",
    "            \"num_rooms\": [\"Habitaciones\"],\n",
    "            \"num_bedrooms\": [\"Dormitorios\"],\n",
    "            \"num_baths\": [\"Baños\"],\n",
    "            \"floor_number\": [\"Piso\"],\n",
    "            \"garage\": [\"Garaje\"],\n",
    "            \"total_surf\": [\"total\"],\n",
    "            \"living_surf\": [\"habitable\"],\n",
    "            \"usable_area\": [\"utilizable\"],\n",
    "            \"floor_type\": [\"Suelo\"],\n",
    "            \"construc_year\": [\"Año\", \"construcción\"],\n",
    "            \"energy_cert_avail\": [\"Certificado\"],\n",
    "            \"heating\": [\"Fuente\"]\n",
    "        }\n",
    "\n",
    "\n",
    "    # Caracteristicas\n",
    "    caracteristicas = soup.find(\"div\", {\"data-test-id\":\"expose-property-features\"})\n",
    "    if caracteristicas:\n",
    "        caracteristicas = caracteristicas.find_all(\"span\", class_=\"sc-4100f4c3-0 bncvQi sc-2f04d979-2 lgHRew\")\n",
    "        list_caracteristicas = {text.get_text() for text in caracteristicas}\n",
    "        for carac in list(list_caracteristicas):\n",
    "            if carac in chain.from_iterable(list(diccionario.values())):\n",
    "                list_caracteristicas.remove(carac)\n",
    "    \n",
    "        v_independ[\"others\"] = list_caracteristicas\n",
    "\n",
    "    # key_info\n",
    "    key_info = soup.find(\"div\", {\"data-test-id\": \"property-details\"})\n",
    "    if key_info:\n",
    "        key_info = key_info.find_all('li')\n",
    "        if key_info:\n",
    "            for li in key_info:\n",
    "                text = li.get_text(strip=True, separator=\"/\")\n",
    "                text = text.split(\"/\")\n",
    "                \n",
    "            \n",
    "                break_ = False\n",
    "                for key, values in diccionario.items():\n",
    "                    for value in values:\n",
    "                        if value in text[0]:\n",
    "                            v_independ[key] = text[1]\n",
    "                            del diccionario[key]\n",
    "                            break_ = True\n",
    "                            break\n",
    "            \n",
    "                    if break_:\n",
    "                        break\n",
    "\n",
    "    # comentario\n",
    "    comentario = soup.find('div', {'data-test-id': 'expose-property-description'})\n",
    "    if comentario:\n",
    "        comentario = comentario.find('p').text.strip()\n",
    "        diccionario[\"coment\"] = comentario\n",
    "\n",
    "    # Reacondicioando de las variables numericas\n",
    "    numericas = [\"num_rooms\", \"num_bedrooms\", \"num_baths\", \"floor_number\", \"garage\", \"total_surf\", \"living_surf\", \"usable_area\", \"construc_year\"]\n",
    "    for num in numericas:\n",
    "        v_independ[num] = text_to_num(v_independ[num])\n",
    "\n",
    "\n",
    "    return v_independ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1096cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Esto es solo para sacar los enlaces de cada articulo, y sus respectivos precios\n",
    "num_max_pag = 2\n",
    "links = []\n",
    "for num_pagina in range(num_max_pag):\n",
    "    url = f\"https://www.engelvoelkers.com/es/es/inmuebles/res/compra/inmobiliario?businessArea[]=residential&currency=EUR&measurementSystem=metric&page={num_pagina}&placeId=ChIJi7xhMnjjQgwR7KNoB5Qs7KY&propertyMarketingType[]=sale&sortingOptions[]=PUBLISHED_AT_DESC&placeName=Espa%C3%B1a\"\n",
    "    # Obtener el HTML de la página\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Buscar todos los <a> con href que contenga \"/es/es/exposes/\"\n",
    "    articulos_pag = soup.find_all('article', attrs={\"data-test-id\":lambda x: x and x.startswith(\"search-components_result-card\")})\n",
    "\n",
    "    for articulo in articulos_pag:\n",
    "        # Sacar el link\n",
    "        enlace = articulo.find_all(\"a\", href=True)\n",
    "        link = enlace[0][\"href\"]\n",
    "\n",
    "        # Sacar el precio\n",
    "        price = articulo.find(\"p\", {\"data-test-id\": \"search-components_result-card_price\"})\n",
    "        if not price:\n",
    "            warnings.warn(f\"El articulo siguiente no tiene precio:{articulo} \")\n",
    "        price = price.text.strip()\n",
    "        price = text_to_num(price)\n",
    "\n",
    "        # Sacar el lugar\n",
    "        place = articulo.find(\"p\", {\"data-test-id\": \"search-components_result-card_location\"}).text.strip()\n",
    "\n",
    "\n",
    "        links.append([link, price, place])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3709af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Ahora itero sobre todos los links que tenemos\n",
    "lectura = []\n",
    "\n",
    "for link in links:\n",
    "    url = f\"https://www.engelvoelkers.com{link[0]}\"\n",
    "    readed_link = read_link(url, link[2])\n",
    "    lectura.append(readed_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e34299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Guardo los datos de la request a las paginas principales\n",
    "encabezados = [\"link\", \"precio\", \"lugar\"]\n",
    "df_links = pd.DataFrame(links, columns=encabezados)\n",
    "df_links.to_csv(\"data_engelyvoelkers/Engelyvolkers_links.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e7df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Guardo los datos de todas las paginas\n",
    "df_lectura = pd.DataFrame(lectura)\n",
    "df_lectura.to_csv(\"data_engelyvoelkers/Engelyvolkers_lectura.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
